{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flaskcode.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kPiQ-Rig4BU",
        "colab_type": "code",
        "outputId": "5d8d216a-0759-4f0f-9ea6-b87478e93ebd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install flask_ngrok\n",
        "!pip install tensorflow==1.15\n",
        "!pip install \"tensorflow_hub>=0.6.0\"\n",
        "!pip3 install tensorflow_text==1.15\n",
        "!pip install -U flask_cors"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask_ngrok in /usr/local/lib/python3.6/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.6/dist-packages (from flask_ngrok) (1.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from flask_ngrok) (2.23.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask_ngrok) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask_ngrok) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask_ngrok) (7.1.2)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask_ngrok) (2.11.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->flask_ngrok) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->flask_ngrok) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->flask_ngrok) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->flask_ngrok) (2.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask_ngrok) (1.1.1)\n",
            "Requirement already satisfied: tensorflow==1.15 in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.10.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.34.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.9.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.28.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.2.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.18.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (46.3.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: tensorflow_hub>=0.6.0 in /usr/local/lib/python3.6/dist-packages (0.8.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub>=0.6.0) (1.18.4)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub>=0.6.0) (3.10.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub>=0.6.0) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow_hub>=0.6.0) (46.3.0)\n",
            "Requirement already satisfied: tensorflow_text==1.15 in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Requirement already satisfied: tensorflow<1.16,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_text==1.15) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.28.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.2.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.15.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.34.2)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.18.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (3.2.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (46.3.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow<1.16,>=1.15.0->tensorflow_text==1.15) (2.10.0)\n",
            "Requirement already up-to-date: flask_cors in /usr/local/lib/python3.6/dist-packages (3.0.8)\n",
            "Requirement already satisfied, skipping upgrade: Flask>=0.9 in /usr/local/lib/python3.6/dist-packages (from flask_cors) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: Six in /usr/local/lib/python3.6/dist-packages (from flask_cors) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.9->flask_cors) (2.11.2)\n",
            "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.9->flask_cors) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.9->flask_cors) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.9->flask_cors) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.9->flask_cors) (1.1.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMwo5SFVlMRs",
        "colab_type": "code",
        "outputId": "c74394e7-63f2-4630-f9c8-1b9b4704d2d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem.porter import *\n",
        "import re\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import networkx as nx\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwKsUAJQxDE5",
        "colab_type": "text"
      },
      "source": [
        "#Module 1 - Fetch Reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAMr1ZXow2dK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import json\n",
        "def getReviews(place):\n",
        "  result={}\n",
        "  \n",
        "  # place = input(\"Enter place name: \")\n",
        "  placeId = requests.get('https://maps.googleapis.com/maps/api/place/findplacefromtext/json?input='+place+'&inputtype=textquery&fields=place_id,photos,formatted_address,name,rating,opening_hours,geometry&key=YOUR_API_KEY')\n",
        "  idJsonText = placeId.text\n",
        "  idText = json.loads(idJsonText)\n",
        "  place_id = idText['candidates'][0]['place_id']\n",
        "  placeDetails = requests.get('https://maps.googleapis.com/maps/api/place/details/json?place_id='+place_id+'&fields=name,rating,reviews&key=YOUR_API_KEY')\n",
        "  jsonText = placeDetails.text\n",
        "  text = json.loads(jsonText)\n",
        "  revList = text['result']['reviews']\n",
        "  passage = \"\"\n",
        "  for rev in revList:\n",
        "    review = rev['text']\n",
        "    passage = passage + review\n",
        "\n",
        "  return passage\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE4s0qE-E4dI",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0677vYFzkWn",
        "colab_type": "text"
      },
      "source": [
        "#Module 2 - Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MO7iYi30fKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contractions = { \n",
        "\"ain't\": \"am not / are not / is not / has not / have not\",\n",
        "\"aren't\": \"are not / am not\",\n",
        "\"can't\": \"cannot\",\n",
        "\"can't've\": \"cannot have\",\n",
        "\"'cause\": \"because\",\n",
        "\"could've\": \"could have\",\n",
        "\"couldn't\": \"could not\",\n",
        "\"couldn't've\": \"could not have\",\n",
        "\"didn't\": \"did not\",\n",
        "\"doesn't\": \"does not\",\n",
        "\"don't\": \"do not\",\n",
        "\"hadn't\": \"had not\",\n",
        "\"hadn't've\": \"had not have\",\n",
        "\"hasn't\": \"has not\",\n",
        "\"haven't\": \"have not\",\n",
        "\"he'd\": \"he had / he would\",\n",
        "\"he'd've\": \"he would have\",\n",
        "\"he'll\": \"he shall / he will\",\n",
        "\"he'll've\": \"he shall have / he will have\",\n",
        "\"he's\": \"he has / he is\",\n",
        "\"how'd\": \"how did\",\n",
        "\"how'd'y\": \"how do you\",\n",
        "\"how'll\": \"how will\",\n",
        "\"how's\": \"how has / how is / how does\",\n",
        "\"I'd\": \"I had / I would\",\n",
        "\"I'd've\": \"I would have\",\n",
        "\"I'll\": \"I shall / I will\",\n",
        "\"I'll've\": \"I shall have / I will have\",\n",
        "\"I'm\": \"I am\",\n",
        "\"I've\": \"I have\",\n",
        "\"isn't\": \"is not\",\n",
        "\"it'd\": \"it had / it would\",\n",
        "\"it'd've\": \"it would have\",\n",
        "\"it'll\": \"it shall / it will\",\n",
        "\"it'll've\": \"it shall have / it will have\",\n",
        "\"it's\": \"it has / it is\",\n",
        "\"let's\": \"let us\",\n",
        "\"ma'am\": \"madam\",\n",
        "\"mayn't\": \"may not\",\n",
        "\"might've\": \"might have\",\n",
        "\"mightn't\": \"might not\",\n",
        "\"mightn't've\": \"might not have\",\n",
        "\"must've\": \"must have\",\n",
        "\"mustn't\": \"must not\",\n",
        "\"mustn't've\": \"must not have\",\n",
        "\"needn't\": \"need not\",\n",
        "\"needn't've\": \"need not have\",\n",
        "\"o'clock\": \"of the clock\",\n",
        "\"oughtn't\": \"ought not\",\n",
        "\"oughtn't've\": \"ought not have\",\n",
        "\"shan't\": \"shall not\",\n",
        "\"sha'n't\": \"shall not\",\n",
        "\"shan't've\": \"shall not have\",\n",
        "\"she'd\": \"she had / she would\",\n",
        "\"she'd've\": \"she would have\",\n",
        "\"she'll\": \"she shall / she will\",\n",
        "\"she'll've\": \"she shall have / she will have\",\n",
        "\"she's\": \"she has / she is\",\n",
        "\"should've\": \"should have\",\n",
        "\"shouldn't\": \"should not\",\n",
        "\"shouldn't've\": \"should not have\",\n",
        "\"so've\": \"so have\",\n",
        "\"so's\": \"so as / so is\",\n",
        "\"that'd\": \"that would / that had\",\n",
        "\"that'd've\": \"that would have\",\n",
        "\"that's\": \"that has / that is\",\n",
        "\"there'd\": \"there had / there would\",\n",
        "\"there'd've\": \"there would have\",\n",
        "\"there's\": \"there has / there is\",\n",
        "\"they'd\": \"they had / they would\",\n",
        "\"they'd've\": \"they would have\",\n",
        "\"they'll\": \"they shall / they will\",\n",
        "\"they'll've\": \"they shall have / they will have\",\n",
        "\"they're\": \"they are\",\n",
        "\"they've\": \"they have\",\n",
        "\"to've\": \"to have\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'd\": \"we had / we would\",\n",
        "\"we'd've\": \"we would have\",\n",
        "\"we'll\": \"we will\",\n",
        "\"we'll've\": \"we will have\",\n",
        "\"we're\": \"we are\",\n",
        "\"we've\": \"we have\",\n",
        "\"weren't\": \"were not\",\n",
        "\"what'll\": \"what shall / what will\",\n",
        "\"what'll've\": \"what shall have / what will have\",\n",
        "\"what're\": \"what are\",\n",
        "\"what's\": \"what has / what is\",\n",
        "\"what've\": \"what have\",\n",
        "\"when's\": \"when has / when is\",\n",
        "\"when've\": \"when have\",\n",
        "\"where'd\": \"where did\",\n",
        "\"where's\": \"where has / where is\",\n",
        "\"where've\": \"where have\",\n",
        "\"who'll\": \"who shall / who will\",\n",
        "\"who'll've\": \"who shall have / who will have\",\n",
        "\"who's\": \"who has / who is\",\n",
        "\"who've\": \"who have\",\n",
        "\"why's\": \"why has / why is\",\n",
        "\"why've\": \"why have\",\n",
        "\"will've\": \"will have\",\n",
        "\"won't\": \"will not\",\n",
        "\"won't've\": \"will not have\",\n",
        "\"would've\": \"would have\",\n",
        "\"wouldn't\": \"would not\",\n",
        "\"wouldn't've\": \"would not have\",\n",
        "\"y'all\": \"you all\",\n",
        "\"y'all'd\": \"you all would\",\n",
        "\"y'all'd've\": \"you all would have\",\n",
        "\"y'all're\": \"you all are\",\n",
        "\"y'all've\": \"you all have\",\n",
        "\"you'd\": \"you had / you would\",\n",
        "\"you'd've\": \"you would have\",\n",
        "\"you'll\": \"you shall / you will\",\n",
        "\"you'll've\": \"you shall have / you will have\",\n",
        "\"you're\": \"you are\",\n",
        "\"you've\": \"you have\"\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVwImN4P0qLI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "contractions_re = re.compile('(%s)' % '|'.join(contractions.keys()))\n",
        "\n",
        "def expand_contractions(s, contractions_dict=contractions):\n",
        "    def replace(match):\n",
        "        return contractions_dict[match.group(0)]\n",
        "    return contractions_re.sub(replace, s)\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnSEfZcm1PV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_freq_table(text_string):\n",
        "    stopwords_list = set(stopwords.words('english'))\n",
        "    \n",
        "    words = word_tokenize(text_string)\n",
        "    \n",
        "    ps = PorterStemmer()\n",
        "    \n",
        "    freq_table = {}\n",
        "    \n",
        "    for word in words:\n",
        "        #stem word \n",
        "        word = ps.stem(word)\n",
        "        \n",
        "        #remove stopwords\n",
        "        if word in stopwords_list: \n",
        "            continue\n",
        "        elif word in freq_table:\n",
        "            freq_table[word] += 1\n",
        "        else:\n",
        "            freq_table[word] = 1\n",
        "            \n",
        "    return freq_table\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piKu4Gqv1Rv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def score_sentences(sentences, freq_table):\n",
        "    \n",
        "    sentence_value = {}\n",
        "    \n",
        "    for sentence in sentences:\n",
        "        word_count_in_sentence = len(word_tokenize(sentence))\n",
        "        \n",
        "        for wordValue in freq_table:\n",
        "            \n",
        "            if wordValue.lower() in sentence.lower():                \n",
        "                if sentence in sentence_value:\n",
        "                    sentence_value[sentence] += freq_table[wordValue]\n",
        "                else:\n",
        "                    sentence_value[sentence] = freq_table[wordValue]\n",
        "\n",
        "        sentence_value[sentence] = sentence_value[sentence] // word_count_in_sentence\n",
        "    return sentence_value\n",
        "\n",
        "def find_average_score(sentence_value):\n",
        "    sum_values = 0\n",
        "    \n",
        "    for entry in sentence_value:\n",
        "        sum_values += sentence_value[entry]\n",
        "        \n",
        "    average = int(sum_values/len(sentence_value))  \n",
        "    return average"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqm7EsnZ0uSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_summary(sentences, sentence_value, threshold):\n",
        "    sentence_count = 0   \n",
        "    summary = ''\n",
        "    \n",
        "    for sentence in sentences:\n",
        "        if sentence in sentence_value and sentence_value[sentence] > threshold:\n",
        "            summary += \" \" + sentence\n",
        "            sentence_count += 1\n",
        "            \n",
        "    return summary \n",
        "            \n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s13ovr2V1XWR",
        "colab_type": "text"
      },
      "source": [
        "#Module 3 - Summarizer 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGDycTSkw7ea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def summary_1(passage):\n",
        "  sentences = sent_tokenize(passage)    \n",
        "  sentences = [expand_contractions(i) for i in sentences]\n",
        "  sentences = [re.sub('\\n', '', i) for i in sentences]\n",
        "  freq_table = create_freq_table(\" \".join(sentences))\n",
        "\n",
        "  sentence_scores = score_sentences(sentences, freq_table)\n",
        "\n",
        "  threshold = find_average_score(sentence_scores)\n",
        "\n",
        "  summary = generate_summary(sentences, sentence_scores, 1.0 * threshold)\n",
        "\n",
        "  #result[\"summary1\"] = re.sub('\\n','',summary)\n",
        "  return summary\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfBiXxxL1Olm",
        "colab_type": "text"
      },
      "source": [
        "#Module 4 - Summarizer 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-fKmLRQqVN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def summary_2(passage):\n",
        "\n",
        "  sentences = sent_tokenize(passage)    \n",
        "  sentences = [expand_contractions(i) for i in sentences]\n",
        "  sentences = [re.sub('\\n', '', i) for i in sentences]\n",
        "\n",
        "  module_url = \"https://tfhub.dev/google/universal-sentence-encoder/2\"\n",
        "\n",
        "  embed = hub.Module(module_url)\n",
        "\n",
        "  # Reduce logging output.\n",
        "  tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "  with tf.Session() as session:\n",
        "      session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "      message_embeddings = session.run(embed(sentences))\n",
        "  \n",
        "\n",
        "  #generate cosine similarity matrix\n",
        "  sim_matrix = cosine_similarity(message_embeddings)\n",
        "\n",
        "  #create graph and generate scores from pagerank algorithms\n",
        "  nx_graph = nx.from_numpy_array(sim_matrix)\n",
        "  scores = nx.pagerank(nx_graph)\n",
        "\n",
        "  ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
        "    \n",
        "  num_of_sentences = 5\n",
        "      \n",
        "  summary = \" \".join([i[1] for i in ranked_sentences[:num_of_sentences]])\n",
        "  #result[\"summary2\"]=summary2\n",
        "\n",
        "  return summary\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUBfhAlfhrBb",
        "colab_type": "code",
        "outputId": "3129f902-4fd4-4315-bd21-be7b04c4c32b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        }
      },
      "source": [
        "\n",
        "from flask import Flask\n",
        "from flask import request\n",
        "from flask_cors import CORS, cross_origin\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)  # Start ngrok when app is run\n",
        "CORS(app)\n",
        "\n",
        "@app.route('/getInput/<place>',methods = ['GET', 'POST'])\n",
        "@cross_origin()\n",
        "def get_placename(place):\n",
        "    reviews={}\n",
        "    passage = getReviews(place)\n",
        "    reviews[\"passage\"]= getReviews(place)\n",
        "    reviews[\"summary1\"] = summary_1(passage)\n",
        "    reviews[\"summary2\"] = summary_2(passage)\n",
        "    \n",
        "    return reviews\n",
        "\n",
        "# for / root, return Hello Word\n",
        "@app.route(\"/\")\n",
        "\n",
        "def root():\n",
        "  \n",
        "    return f\"Hello World! \"\n",
        "\n",
        "app.run()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://d371a04c.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/May/2020 14:32:12] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [18/May/2020 14:32:12] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [18/May/2020 14:32:45] \"\u001b[37mGET /getInput/lulu%20mall HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/May/2020 14:32:45] \"\u001b[37mGET /getInput/lulu%20mall HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [18/May/2020 14:35:47] \"\u001b[37mGET /getInput/nit%20calicut HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/May/2020 14:35:47] \"\u001b[37mGET /getInput/nit%20calicut HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [18/May/2020 14:35:53] \"\u001b[37mGET /getInput/nit%20calicut HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/May/2020 14:35:53] \"\u001b[37mGET /getInput/nit%20calicut HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [18/May/2020 14:35:59] \"\u001b[37mGET /getInput/calicut%20paragon HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/May/2020 14:35:59] \"\u001b[37mGET /getInput/calicut%20paragon HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [18/May/2020 14:36:12] \"\u001b[37mGET /getInput/calicut%20paragon HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/May/2020 14:36:12] \"\u001b[37mGET /getInput/calicut%20paragon HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [18/May/2020 14:36:19] \"\u001b[37mGET /getInput/calicut%20paragon HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/May/2020 14:36:19] \"\u001b[37mGET /getInput/calicut%20paragon HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [18/May/2020 14:36:24] \"\u001b[37mGET /getInput/kozhikode%20beach HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/May/2020 14:36:24] \"\u001b[37mGET /getInput/kozhikode%20beach HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [18/May/2020 14:36:41] \"\u001b[37mGET /getInput/calicut%20beach HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/May/2020 14:36:41] \"\u001b[37mGET /getInput/calicut%20beach HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [18/May/2020 14:36:59] \"\u001b[37mGET /getInput/kozhikode%20beach HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/May/2020 14:36:59] \"\u001b[37mGET /getInput/kozhikode%20beach HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [18/May/2020 14:37:24] \"\u001b[37mGET /getInput/kochi%20airport HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/May/2020 14:37:24] \"\u001b[37mGET /getInput/kochi%20airport HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [18/May/2020 14:37:59] \"\u001b[37mGET /getInput/kozhikode%20medical%20college HTTP/1.1\u001b[0m\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [18/May/2020 14:37:59] \"\u001b[37mGET /getInput/kozhikode%20medical%20college HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}